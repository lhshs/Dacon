{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36de8d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:22:00.374512Z",
     "start_time": "2022-12-16T09:21:57.819879Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for graphing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b188f75c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:22:00.377110Z",
     "start_time": "2022-12-16T09:22:00.375761Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/lhs/Desktop/GitHub/Dacon/221223_Sentence_Category_Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54638467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:22:00.443577Z",
     "start_time": "2022-12-16T09:22:00.377889Z"
    }
   },
   "outputs": [],
   "source": [
    "train_original = pd.read_csv('data/train.csv')\n",
    "train_original.drop(columns=['ID'], inplace=True)\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test.drop(columns=['ID'], inplace=True)\n",
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1731d97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:22:03.305511Z",
     "start_time": "2022-12-16T09:22:03.296210Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "CFG = {\n",
    "    'EPOCHS':20,\n",
    "    'LEARNING_RATE':1e-5,\n",
    "    'BATCH_SIZE':32,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c1839d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:22:39.907229Z",
     "start_time": "2022-12-16T09:22:39.893608Z"
    }
   },
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(train_original, train_original['label'], test_size=0.2, random_state=CFG['SEED'])\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782539c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:24:03.934242Z",
     "start_time": "2022-12-16T09:23:39.474496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af2133d578d402394291214f8346286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/545 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0d4854a94b46d38733329edc18a8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/273M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3de525c92514f69ba364bc3a3c88b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/375 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5c61db36a24e26aa176bb8b2845510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9c6087ffb1402fae4a689dee1626c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/752k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c53ab9a31d2415f85b9a625e0d31e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_nm = 'klue/roberta-small'\n",
    "base_model = AutoModel.from_pretrained(model_nm)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2331abae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:24:44.197926Z",
     "start_time": "2022-12-16T09:24:43.226270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaWElEQVR4nO3df5BV533f8fdH7A+hRfzSLgwBHHBL1CBPjdwNdayMm1hKhN0kKG2kbKZJNx5a6hqC3cZuIZ6pkz+YUavIk0xi3OIf8lYxohv9GGGnYxs2tjWZpIKVjGUhRMFGRmso3AtVlwCzsPDtH/fco8vu3d27wLm/9vOa2TnnPuc5l+/hCH33ec55nkcRgZmZGcBttQ7AzMzqh5OCmZmlnBTMzCzlpGBmZiknBTMzS7XUOoCb0dnZGStWrKh1GGZmDeWll17KR0RXuWMNnRRWrFjB4OBgrcMwM2sokn400TF3H5mZWcpJwczMUk4KZmaWclIwM7OUk4KZmaWcFMzMLOWkYGZmqUyTgqR/J+mQpFclPSXpdkkLJe2VdDTZLiipv03SMUlHJD2YZWxmZjZeZklB0lJgC9AdEe8CZgE9wFZgICJWAQPJZyStTo7fA6wDdkialVV8t0pEkMvlyOVyeG0KM2t0WXcftQCzJbUAdwAngfVAX3K8D3go2V8P7I6IkYg4DhwD1mYc303L5/P07thH74595PP5WodjZnZTMksKEfFj4I+AE8Ap4P9FxDeBxRFxKqlzCliUnLIUeLPkK4aSsutI2ihpUNJgLpfLKvxpaZszj7Y582odhpnZTcuy+2gBhd/+VwI/AXRI+q3JTilTNq4/JiJ2RkR3RHR3dZWdz8nMzG5Qlt1HDwDHIyIXEVeAZ4H3AaclLQFItmeS+kPA8pLzl1HobmoYfr5gZo0uy6RwAnivpDskCbgfOAzsAXqTOr3A88n+HqBHUruklcAqYH+G8d1yZ8+e9fMFM2tomU2dHREvSnoaeBkYBb4L7ATmAP2SNlBIHA8n9Q9J6gdeS+pvioirWcWXFT9bMLNGlul6ChHxaeDTY4pHKLQaytXfDmzPMqZqiAjy+TydnZ0UGklmZo3BI5pvUPH5QbluossXhvnI5wfchWRmDaehV16rpeL4hJELw8xeuISW1uv/KtvumFujyMzMbpyTwk1omzNv/DuzZmYNzN1HZmaWclIwM7OUk4KZmaWcFMzMLOWkYGZmKScFMzNLOSmYmVnKScHMzFJOCmZmlnJSMDOzlJOCmZmlnBTMzCzlpGBmZiknBTMzS2WWFCTdLelgyc+wpI9LWihpr6SjyXZByTnbJB2TdETSg1nFZmZm5WWWFCLiSESsiYg1wD8CLgLPAVuBgYhYBQwkn5G0GugB7gHWATskzcoqPjMzG69a3Uf3Az+IiB8B64G+pLwPeCjZXw/sjoiRiDgOHAPWVik+MzOjekmhB3gq2V8cEacAku2ipHwp8GbJOUNJ2XUkbZQ0KGkwl8tlGLKZ2cyTeVKQ1Ab8KvAXU1UtUzZutcuI2BkR3RHR3dXVdStCzEREkM/nyeVyRHjRTjNrDNVoKXwQeDkiTiefT0taApBszyTlQ8DykvOWASerEF8mrlw8z5ZdB+jdsY98Pl/rcMzMKlKNpPCbvN11BLAH6E32e4HnS8p7JLVLWgmsAvZXIb7MtHfMp23OvFqHYWZWsZYsv1zSHcAvAv+mpPhRoF/SBuAE8DBARByS1A+8BowCmyLiapbxmZnZ9TJNChFxEbhrTNlZCm8jlau/HdieZUxmZjYxj2g2M7OUk4KZmaUy7T5qNsXXTIv7ZmbNxklhGvL5PL079gHw+CNrahuMmVkGnBSmya+Ymlkz8zMFMzNLOSmYmVnKScHMzFJOCmZmlnJSMDOzlJOCmZmlnBTMzCzlpGBmZiknBTMzSzkpmJlZyknBzMxSmSYFSfMlPS3pdUmHJf2spIWS9ko6mmwXlNTfJumYpCOSHswytmqLCHK5nGdXNbO6lnVL4U+Ar0fEPwDeDRwGtgIDEbEKGEg+I2k10APcA6wDdkialXF8VZPP5+l57Jl06m0zs3qUWVKQNBd4P/BFgIi4HBFvAeuBvqRaH/BQsr8e2B0RIxFxHDgGrM0qvlpou2NurUMwM5tUli2FdwI54AlJ35X0BUkdwOKIOAWQbBcl9ZcCb5acP5SUXUfSRkmDkgZzuVyG4b+t2PXj3/LNrNllmRRagPcAn4uIe4ELJF1FE1CZsnEd8BGxMyK6I6K7q6vr1kQ6heLiOpufeIHRK6NV+TPNzGohy6QwBAxFxIvJ56cpJInTkpYAJNszJfWXl5y/DDiZYXzT0jZnHm0d7v4xs+aWWVKIiP8DvCnp7qTofuA1YA/Qm5T1As8n+3uAHkntklYCq4D9WcVnZmbjZb0c5+8CX5HUBvwQ+DCFRNQvaQNwAngYICIOSeqnkDhGgU0RcTXj+MzMrESmSSEiDgLdZQ7dP0H97cD2LGMyM7OJeUSzmZmlsu4+shIRkb7W2tnZiVTuhSszs9pxS6GKrlw8z5ZdB+jdsc9jHsysLrmlUGXtHfNpafVfu5nVJ7cUzMws5aRgZmYpJwUzM0s5KZiZWcpJwczMUk4KZmaWclIwM7OUk4KZmaWcFMzMLOWkYGZmKScFMzNLOSmYmVnKScHMzFKZJgVJb0j6vqSDkgaTsoWS9ko6mmwXlNTfJumYpCOSHswyNjMzG68aLYVfiIg1EVFclnMrMBARq4CB5DOSVgM9wD3AOmCHpFlViM/MzBK16D5aD/Ql+33AQyXluyNiJCKOA8eAtdUPz8xs5so6KQTwTUkvSdqYlC2OiFMAyXZRUr4UeLPk3KGk7DqSNkoalDSYy+UyDN3MbObJegmw+yLipKRFwF5Jr09St9yCxTGuIGInsBOgu7t73HEzM7txmbYUIuJksj0DPEehO+i0pCUAyfZMUn0IWF5y+jLgZJbxmZnZ9TJLCpI6JN1Z3Ad+CXgV2AP0JtV6geeT/T1Aj6R2SSuBVcD+rOIzM7Pxsuw+Wgw8J6n45+yKiK9LOgD0S9oAnAAeBoiIQ5L6gdeAUWBTRFzNMD4zMxsjs6QQET8E3l2m/Cxw/wTnbAe2ZxWTmZlNziOazcws5aRgZmapipKCpPsqKbPpiQhyuRwRfrPWzOpDpS2FP62wzKYhn8/T89gz5PP5WodiZgZM8aBZ0s8C7wO6JP37kkNzAc9LdAu03TG31iGYmaWmevuoDZiT1LuzpHwY+PWsgjIzs9qYNClExHeA70j6ckT8qEox1YWISLt13OdvZjNFpeMU2iXtBFaUnhMRH8giqHqQz+fp3bEPgMcfWVPbYMzMqqTSpPAXwH8FvgDMmFHGbXPm1ToEM7OqqjQpjEbE5zKNxMzMaq7SV1K/KumjkpYky2kulLQw08jMzKzqKm0pFGc1/WRJWQDvvLXhmJlZLVWUFCJiZdaBzFSlbzl1dnaSzCprZlYTFSUFSf+yXHlE/PdbG87Mc+XiebbsOkBrSyt9H32Arq6uWodkZjNYpd1HP1OyfzuFqa9fBpwUboH2jvm0tGa9MqqZ2dQq7T763dLPkuYBT2YSkZmZ1cyNTp19kcJymWZm1kQqfabwVQpvG0FhIryfBvorPHcWMAj8OCJ+OXmV9X9QGB39BvBIRPzfpO42YAOFAXJbIuIbFV+JmZndtEo7sv+oZH8U+FFEDFV47seAwxRmVgXYCgxExKOStiaf/6Ok1UAPcA/wE8A+ST/VKOs0RwTnzp2rdRhmZjelou6jZGK81ynMlLoAuFzJeZKWAf+UwvQYReuBvmS/D3iopHx3RIxExHHgGLC2kj+nHly+MMwnnnyB0SujtQ7FzOyGVbry2iPAfuBh4BHgRUmVTJ39x8B/AK6VlC2OiFMAyXZRUr4UeLOk3lBSNjaWjZIGJQ3mcrlKwq+attl3Tl3JzKyOVdp99CngZyLiDICkLmAf8PREJ0j6ZeBMRLwk6ecr+DPKjdoaN2d1ROwEdgJ0d3fXZE5rdxWZWbOq9O2j24oJIXG2gnPvA35V0hvAbuADkv4cOC1pCUCyLX7vELC85PxlwMkK46sqdxWZWbOqNCl8XdI3JP2OpN8B/hL4n5OdEBHbImJZRKyg8AD5ryLit4A9vD2XUi/wfLK/B+iR1C5pJYVXXvdP62qqyF1FZtaMplqj+e9TeAbwSUn/DPg5Ct08fwt85Qb/zEeBfkkbgBMUnlMQEYck9QOvUXjDaVOjvHlkZtYspnqm8MfA7wNExLPAswCSupNjv1LJHxIR3wa+neyfpTBNRrl624HtlXynmZndelN1H62IiFfGFkbEIIXBZ00nIsjlcunMpWZmM8lULYXbJzk2+1YGUi+KazOPXBhm9sIlnqjOzGaUqVoKByT967GFyfOAl7IJqfba5syjrWPu1BXNzJrMVL8Gfxx4TtK/4O0k0A20Ab+WYVxmZlYDkyaFiDgNvE/SLwDvSor/MiL+KvPIzMys6ipdT+FbwLcyjsXMzGrsRtdTMDOzJuSkYGZmKScFMzNLOSmYmVnKI7MyFhHTGh1drN/Z2YlUbjZxM7PsuKWQscsXhtmy6wCbn3iB0dGpp9rO5/P0PPaMp9kws5pwUqiC9o750xoh3XaHR1ObWW04KZiZWcpJwczMUn7QXIdKH077gbOZVVNmLQVJt0vaL+l7kg5J+sOkfKGkvZKOJtsFJedsk3RM0hFJD2YVW727cvE8W3YdoHfHPj9wNrOqyrL7aAT4QES8G1gDrJP0XmArMBARq4CB5DOSVlNYy/keYB2wQ9KsDOOra+0d82mbM6/WYZjZDJNZUoiCv0s+tiY/AawH+pLyPuChZH89sDsiRiLiOHAMWJtVfGZmNl6mD5olzZJ0EDgD7I2IF4HFEXEKINkuSqovBd4sOX0oKTMzsyrJNClExNWIWAMsA9ZKetck1cs9TY1xlaSNkgYlDeZyuVsUqZmZQZVeSY2It4BvU3hWcFrSEoBkeyapNgQsLzltGXCyzHftjIjuiOju6urKMmwzsxkny7ePuiTNT/ZnAw8ArwN7gN6kWi/wfLK/B+iR1C5pJbAK2J9VfGZmNl6W4xSWAH3JG0S3Af0R8TVJfwv0S9oAnAAeBoiIQ5L6gdeAUWBTRFzNMD4zMxsjs6QQEa8A95YpPwvcP8E524HtWcVkZmaT8zQXU4gIzp07V+swzMyqwklhCpcvDPOJJ19g9MrU016bmTU6J4UKtM2+s9YhmJlVhZOCmZmlnBTMzCzlpGBmZimvp1ADpeslmJnVEyeFGrh8YZgtuw5wbeQSo6N+q8nM6oe7j2qkvWM+bR1zax2Gmdl1nBQaQESQy+WIGDdprJnZLeWk0ADy+Tw9jz3j5xBmljknhQbRdoe7mswse04KZmaWclIwM7OUk4KZmaWcFMzMLOWkYGZmqSzXaF4u6VuSDks6JOljSflCSXslHU22C0rO2SbpmKQjkh7MKjYzMysvy5bCKPB7EfHTwHuBTZJWA1uBgYhYBQwkn0mO9QD3AOuAHcn6zjNCcT6kSscieECbmWUhs6QQEaci4uVk/zxwGFgKrAf6kmp9wEPJ/npgd0SMRMRx4BiwNqv46k1xPqTNT7xQdj6kYtIoJgIPaDOzLFTlmYKkFcC9wIvA4og4BYXEASxKqi0F3iw5bSgpG/tdGyUNShrM5XKZxl1tk82HdOXiebbsOkDvjn1pIvCANjO71TJPCpLmAM8AH4+I4cmqlikb1zcSETsjojsiuru6um5VmA2hvWM+bXPm1ToMM2timSYFSa0UEsJXIuLZpPi0pCXJ8SXAmaR8CFhecvoy4GSW8ZmZ2fWyfPtIwBeBwxHxmZJDe4DeZL8XeL6kvEdSu6SVwCpgf1bxmZnZeFkusnMf8NvA9yUdTMp+H3gU6Je0ATgBPAwQEYck9QOvUXhzaVNEXM0wPjMzGyOzpBARf0355wQA909wznZge1YxmZnZ5Dyi2czMUk4KZmaWclIwM7OUk4KZmaWyfPuoYRSnjSjum5nNVE4KQD6fp3fHPgAef2RNbYOZhtJk1tnZSWFoiJnZjXNSSDTi9BHF+ZBaZrXwmd+4l87OTicHM7spfqbQ4No75oM0brI8M7Mb4ZZCk2jvmE9Lq2+nmd0ctxTMzCzlpFAiIjh37lytwzAzqxknhRKXLwzziSdfYPTK+JXPzMxmAieFMdpm31nrEMzMasZPJutY6TgEM7NqcFKoY5cvDLNl1wGujVxidNRdWmaWPSeFOtfeMZ+rLa2MvnW2ovoRQS6XS6frkOQBbWZWMSeFJnP27Fl+r/8gIxeGua19Nq0trfR99AG6urpqHZqZNYAs12j+kqQzkl4tKVsoaa+ko8l2QcmxbZKOSToi6cGs4poJ2ubMo61jLu0d8xty+g4zq50s3z76MrBuTNlWYCAiVgEDyWckrQZ6gHuSc3ZImpVhbGZmVkZmSSEiXgDGjgRbD/Ql+33AQyXluyNiJCKOA8eAtVnFZmZm5VX7mcLiiDgFEBGnJC1KypcC/6uk3lBSNo6kjcBGgHe84x0Zhlqf/JqqmWWpXh40l3s1puxqNxGxE9gJ0N3dPeNWxPFrqmaWpWqPaD4taQlAsj2TlA8By0vqLQNOZh1M8fXNRvvNu71jPm0dc2sdhpk1oWonhT1Ab7LfCzxfUt4jqV3SSmAVsD/rYIorrm1+ornnOyomv9LxC2Zm5WTWfSTpKeDngU5JQ8CngUeBfkkbgBPAwwARcUhSP/AaMApsioirWcVWqm3OvPL9VE2kOHYB8JgFM5tUZkkhIn5zgkP3T1B/O7A9q3hmurHjFby+s5mV41lSZ6hi15mX8DSzUvXy9pFVQWnrICI82tnMxnFSaCJTrRxXfJ21taWVxx9ZU73AzKxhuPuoiVSycpznQzKzybil0GSmu3KcHzibWSm3FJpcpV1KfuBsZuCk0PTcpWRm0+HuoxlgbJfSVK2H0i6lu+66i7NnC6u+uXvJrPk5KcxAhdbDK9y14p7rykvngiqOgH78kTUeDW02gzgpzFDlHkiXLuU5e+ESWloL/3m0zZnnB9JmM4STgl1normgSsc4uMVg1rycFAyY+jkDFB5IF1sPZtacZuzbR17B7HqVvKUEb/+9eQpus+Y0Y5NCPp9n42e/1tTrKExXJQPfLl8Y5iOfH0gTg9dpMGsuM7ovYLqjf62gdfad5PP5695SGvucodii8ENps8YyY1sKNrWJnjNcuXieLbsOsPmJF7itvYPWjrnjupTy+Tw9jz3jFoVZg3FSsAlN9pyhdJ3ocl1K+XyetjsKxydbu6FYPyKmTB5OLmbZq7vuI0nrgD8BZgFfiIhHaxzSjFZpF9vYLqWRC8Pc1jb77e8pGevQ2dkJkNbf/MR32P3Jfw5A7459AHz5396fdjsV67/++useSGeWsbpKCpJmAZ8FfhEYAg5I2hMRr9U2MptKsUvp2sglZi9cQhtw5fLl61oGxRbF09sK/5Pv3bGPkQvDqHV2Wq+YPI4ePcr2fSeICD7zG/cCsPGzX2PesrvT12KLLQcASenzi3JvSEUEkq6rV3ps7MC8WzFYz89VrBHVVVIA1gLHIuKHAJJ2A+uBTJLC5Uvnue3CW1wbucRto1e4NnKJy5fOM3ILym7V9zRSWducQndR8djF4XN85PMDXLt8idsXLObayCWAcV1IF86eHFfvY//tb1jwk3dzbeRSemx0dLTw3S2taSvjw489Rfv8RbS0tPBnH/4ndHZ2pq2PyxfPc1vbbK5dvsSl4bfo6FxyXb2iYn1g3HeUlk1XPp9n4599lZ2bf+WGzjebTFYtZdVT36ykXwfWRcS/Sj7/NvCPI2JzSZ2NwMbk493AkQq+uhNo9EEJvob60AzXAM1xHb6GG/eTEVE2q9RbS6FcG/u6rBURO4Gd0/pSaTAium8msFrzNdSHZrgGaI7r8DVko97ePhoClpd8XgacrFEsZmYzTr0lhQPAKkkrJbUBPcCeGsdkZjZj1FX3UUSMStoMfIPCK6lfiohDt+Crp9XdVKd8DfWhGa4BmuM6fA0ZqKsHzWZmVlv11n1kZmY15KRgZmappk4KktZJOiLpmKSttY6nUpLekPR9SQclDSZlCyXtlXQ02S6odZxjSfqSpDOSXi0pmzBuSduSe3NE0oO1ifp6E1zDH0j6cXI/Dkr6UMmxeryG5ZK+JemwpEOSPpaUN8y9mOQaGuZeSLpd0n5J30uu4Q+T8vq+D8WJyJrth8KD6h8A7wTagO8Bq2sdV4WxvwF0jin7L8DWZH8r8J9rHWeZuN8PvAd4daq4gdXJPWkHVib3aladXsMfAJ8oU7der2EJ8J5k/07gfyexNsy9mOQaGuZeUBh3NSfZbwVeBN5b7/ehmVsK6ZQZEXEZKE6Z0ajWA33Jfh/wUO1CKS8iXgDGzrU9Udzrgd0RMRIRx4FjFO5ZTU1wDROp12s4FREvJ/vngcPAUhroXkxyDROpx2uIiPi75GNr8hPU+X1o5qSwFHiz5PMQk/9HVU8C+Kakl5JpPQAWR8QpKPyDARbVLLrpmSjuRrs/myW9knQvFZv7dX8NklYA91L4LbUh78WYa4AGuheSZkk6CJwB9kZE3d+HZk4KU06ZUcfui4j3AB8ENkl6f60DykAj3Z/PAX8PWAOcAh5Pyuv6GiTNAZ4BPh4Rw5NVLVNWF9dR5hoa6l5ExNWIWENhdoa1kt41SfW6uIZmTgoNO2VGRJxMtmeA5yg0IU9LWgKQbM/ULsJpmSjuhrk/EXE6+cd9Dfg8bzfp6/YaJLVS+J/pVyLi2aS4oe5FuWtoxHsBEBFvAd8G1lHn96GZk0JDTpkhqUPSncV94JeAVynE3ptU6wWer02E0zZR3HuAHkntklYCq4D9NYhvSsV/wIlfo3A/oE6vQZKALwKHI+IzJYca5l5MdA2NdC8kdUman+zPBh4AXqfe70Mtn85n/QN8iMJbCz8APlXreCqM+Z0U3kD4HnCoGDdwFzAAHE22C2sda5nYn6LQpL9C4beeDZPFDXwquTdHgA/WOv5JruFJ4PvAKxT+4S6p82v4OQrdDq8AB5OfDzXSvZjkGhrmXgD/EPhuEuurwH9Kyuv6PniaCzMzSzVz95GZmU2Tk4KZmaWcFMzMLOWkYGZmKScFMzNLOSmYmVnKScHMzFL/H6vcQ87VVT3fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log value : 90.4092368060602\n"
     ]
    }
   ],
   "source": [
    "tokenizer_len = [len(tokenizer(s)['input_ids']) for s in train['문장']]\n",
    "sns.histplot(tokenizer_len)\n",
    "plt.show()\n",
    "\n",
    "print(f'log value : {np.mean(tokenizer_len)+3*np.std(tokenizer_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c3873b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:25:01.010469Z",
     "start_time": "2022-12-16T09:25:00.885674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log value : 4.8974082584991345\n",
      "original value : 133.94218592094492\n"
     ]
    }
   ],
   "source": [
    "tokenizer_log = np.log(tokenizer_len)\n",
    "sns.histplot(tokenizer_log)\n",
    "plt.show()\n",
    "\n",
    "print(f'log value : {np.mean(tokenizer_log)+3*np.std(tokenizer_log)}')\n",
    "print(f'original value : {np.exp(np.mean(tokenizer_log)+3*np.std(tokenizer_log))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33fe1b88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:25:56.294875Z",
     "start_time": "2022-12-16T09:25:56.273752Z"
    }
   },
   "outputs": [],
   "source": [
    "class SentenceTypeDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, labels=None):\n",
    "        texts = dataframe['문장'].values.tolist()\n",
    "\n",
    "        self.texts = [tokenizer(text, padding='max_length', max_length=90, truncation=True, return_tensors='pt') for text in texts]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "\n",
    "        if self.labels is not None:\n",
    "            type_tmp = self.labels['type'][idx]\n",
    "            polarity_tmp = self.labels['polarity'][idx]\n",
    "            tense_tmp = self.labels['tense'][idx]\n",
    "            certainty_tmp = self.labels['certainty'][idx]\n",
    "            return text, torch.Tensor(type_tmp), torch.Tensor(polarity_tmp), torch.Tensor(tense_tmp), torch.Tensor(certainty_tmp)\n",
    "        else:\n",
    "            return text, torch.Tensor([-1,-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "985983a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:26:12.043182Z",
     "start_time": "2022-12-16T09:26:12.033393Z"
    }
   },
   "outputs": [],
   "source": [
    "class SentenceClassifier(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.klue = base_model # from transformers package\n",
    "\n",
    "        self.fc1 = nn.Linear(768, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.type_clf = nn.Linear(32,4)\n",
    "        self.polarity_clf = nn.Linear(32,3)\n",
    "        self.tense_clf = nn.Linear(32,3)\n",
    "        self.certainty_clf = nn.Linear(32,2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # input_ids : token's id / attention_mask : make a model to focus on which token\n",
    "        klue_out = self.klue(input_ids= input_ids, attention_mask = attention_mask)[0][:,0]\n",
    "\n",
    "        x = self.fc1(klue_out)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        type_output = self.type_clf(x)\n",
    "        type_output = self.softmax(type_output)\n",
    "        polarity_output = self.polarity_clf(x)\n",
    "        polarity_output = self.softmax(polarity_output)\n",
    "        tense_output = self.tense_clf(x)\n",
    "        tense_output = self.softmax(tense_output)\n",
    "        certainty_output = self.certainty_clf(x)\n",
    "        certainty_output = self.softmax(certainty_output)\n",
    "\n",
    "        return type_output, polarity_output, tense_output, certainty_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2352a12b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:26:45.897394Z",
     "start_time": "2022-12-16T09:26:45.873276Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_train(model, train_dataloader, val_dataloader, learning_rate, epochs, model_nm):\n",
    "    best_val_loss = 99999999999999 # setting max (act as infinity)\n",
    "    early_stopping_threshold_count = 0\n",
    "\n",
    "    criterion = {\n",
    "        'type' : nn.CrossEntropyLoss().to(device),\n",
    "        'polarity' : nn.CrossEntropyLoss().to(device),\n",
    "        'tense' : nn.CrossEntropyLoss().to(device),\n",
    "        'certainty' : nn.CrossEntropyLoss().to(device)\n",
    "    }\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        model.train() # sets into the training mode\n",
    "        \n",
    "        for train_input, type_label, polarity_label, tense_label, certainty_label in tqdm(train_dataloader):\n",
    "            attention_mask = train_input['attention_mask'].to(device)\n",
    "            input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
    "            type_label = type_label.to(device)\n",
    "            polarity_label = polarity_label.to(device)\n",
    "            tense_label = tense_label.to(device)\n",
    "            certainty_label = certainty_label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            type_output, polarity_output, tense_output, certainty_output = model(input_ids, attention_mask) # from the forward function\n",
    "            \n",
    "            loss = 0.25*criterion['type'](type_output, type_label.float()) + \\\n",
    "                   0.25*criterion['polarity'](polarity_output, polarity_label.float()) + \\\n",
    "                   0.25*criterion['tense'](tense_output, tense_label.float()) + \\\n",
    "                   0.25*criterion['certainty'](certainty_output, certainty_label.float())\n",
    "            total_loss_train += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        with torch.no_grad(): # since we should not change gradient for validation \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "            \n",
    "            model.eval() # deactivate training\n",
    "            \n",
    "            # same process as the above\n",
    "            for val_input, vtype_label, vpolarity_label, vtense_label, vcertainty_label in tqdm(val_dataloader):\n",
    "                attention_mask = val_input['attention_mask'].to(device)\n",
    "                input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                vtype_label = vtype_label.to(device)\n",
    "                vpolarity_label = vpolarity_label.to(device)\n",
    "                vtense_label = vtense_label.to(device)\n",
    "                vcertainty_label = vcertainty_label.to(device)\n",
    "                \n",
    "                vtype_output, vpolarity_output, vtense_output, vcertainty_output = model(input_ids, attention_mask) # from the forward function\n",
    "\n",
    "                loss = 0.25*criterion['type'](vtype_output, vtype_label.float()) + \\\n",
    "                        0.25*criterion['polarity'](vpolarity_output, vpolarity_label.float()) + \\\n",
    "                        0.25*criterion['tense'](vtense_output, vtense_label.float()) + \\\n",
    "                        0.25*criterion['certainty'](vcertainty_output, vcertainty_label.float())\n",
    "\n",
    "                total_loss_val += loss.item()\n",
    "\n",
    "            \n",
    "            print(f'Epochs: {epoch + 1} '\n",
    "                  f'| Train Loss: {total_loss_train / len(train_dataloader): .3f} '\n",
    "                  f'| Train Accuracy: {total_acc_train / (len(train_dataloader.dataset)): .3f} '\n",
    "                  f'| Val Loss: {total_loss_val / len(val_dataloader): .3f} '\n",
    "                  f'| Val Accuracy: {total_acc_val / len(val_dataloader.dataset): .3f}')\n",
    "            \n",
    "            if best_val_loss > total_loss_val:\n",
    "                best_val_loss = total_loss_val # saving only the best one\n",
    "                torch.save(model, f\"model/{model_nm}.pt\")\n",
    "                print(\"Saved model\")\n",
    "                early_stopping_threshold_count = 0\n",
    "            else:\n",
    "                early_stopping_threshold_count += 1 # checking how many epochs have passed that val_loss didn't increase\n",
    "                \n",
    "            if early_stopping_threshold_count >= 3: # ==> patience=1\n",
    "                print(\"Early stopping\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06d5402f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:26:54.648291Z",
     "start_time": "2022-12-16T09:26:54.615617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>유형_대화형</th>\n",
       "      <th>유형_사실형</th>\n",
       "      <th>유형_예측형</th>\n",
       "      <th>유형_추론형</th>\n",
       "      <th>극성_긍정</th>\n",
       "      <th>극성_미정</th>\n",
       "      <th>극성_부정</th>\n",
       "      <th>시제_과거</th>\n",
       "      <th>시제_미래</th>\n",
       "      <th>시제_현재</th>\n",
       "      <th>확실성_불확실</th>\n",
       "      <th>확실성_확실</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>용산구청 관계자는 ＂재정이 열악한 지자체로서는 1800억원을 마련할 수 없다＂며 서...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>부산시는 이처럼 부산이 가파른 상승세를 보이는 이유에 대해 지난해부터 추진하고 있는...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그러나 미숙아, 만성호흡기질환, 선천 심장병, 선천 면역결핍질환, 암환자 등의 고위...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>탁구 종목에서 중국 대표팀 위상이 뛰어나기 때문이다.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이 논문에 따르면 ＇BT-11＇은 뇌의 신경전달물질인 아세틸콜린을 분해하는 효소의 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>우리가 익히 아는 대로 임꺽정은 신출귀몰했다.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13228</th>\n",
       "      <td>김 상무보는 ＂실제 이용자 수와 인당 사용시간 등 주요 데이터가 매년 두 자릿수 상...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>＇디폴트 옵션＇의 필요성을 주장해온 쪽이 항상 사례로 들어온 것이 ＇401K＇로 불...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13230</th>\n",
       "      <td>1992년부터 선양시 조선족노인협회를 후원하기 시작해 1997년에는 1500㎡ 건물...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13231</th>\n",
       "      <td>차량은 고속 상태지만 운전자는 정체모드에서 사고가 많이 발생한다.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13232 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      문장  유형_대화형  유형_사실형  \\\n",
       "0      용산구청 관계자는 ＂재정이 열악한 지자체로서는 1800억원을 마련할 수 없다＂며 서...       0       1   \n",
       "1      부산시는 이처럼 부산이 가파른 상승세를 보이는 이유에 대해 지난해부터 추진하고 있는...       0       1   \n",
       "2      그러나 미숙아, 만성호흡기질환, 선천 심장병, 선천 면역결핍질환, 암환자 등의 고위...       0       1   \n",
       "3                          탁구 종목에서 중국 대표팀 위상이 뛰어나기 때문이다.       0       0   \n",
       "4      이 논문에 따르면 ＇BT-11＇은 뇌의 신경전달물질인 아세틸콜린을 분해하는 효소의 ...       0       1   \n",
       "...                                                  ...     ...     ...   \n",
       "13227                          우리가 익히 아는 대로 임꺽정은 신출귀몰했다.       0       1   \n",
       "13228  김 상무보는 ＂실제 이용자 수와 인당 사용시간 등 주요 데이터가 매년 두 자릿수 상...       0       1   \n",
       "13229  ＇디폴트 옵션＇의 필요성을 주장해온 쪽이 항상 사례로 들어온 것이 ＇401K＇로 불...       1       0   \n",
       "13230  1992년부터 선양시 조선족노인협회를 후원하기 시작해 1997년에는 1500㎡ 건물...       0       1   \n",
       "13231               차량은 고속 상태지만 운전자는 정체모드에서 사고가 많이 발생한다.       0       1   \n",
       "\n",
       "       유형_예측형  유형_추론형  극성_긍정  극성_미정  극성_부정  시제_과거  시제_미래  시제_현재  확실성_불확실  \\\n",
       "0           0       0      1      0      0      1      0      0        0   \n",
       "1           0       0      1      0      0      1      0      0        0   \n",
       "2           0       0      1      0      0      0      0      1        0   \n",
       "3           0       1      1      0      0      0      0      1        0   \n",
       "4           0       0      1      0      0      0      0      1        0   \n",
       "...       ...     ...    ...    ...    ...    ...    ...    ...      ...   \n",
       "13227       0       0      1      0      0      1      0      0        0   \n",
       "13228       0       0      1      0      0      1      0      0        0   \n",
       "13229       0       0      1      0      0      0      0      1        0   \n",
       "13230       0       0      1      0      0      1      0      0        0   \n",
       "13231       0       0      1      0      0      0      0      1        0   \n",
       "\n",
       "       확실성_확실  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "13227       1  \n",
       "13228       1  \n",
       "13229       1  \n",
       "13230       1  \n",
       "13231       1  \n",
       "\n",
       "[13232 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp = train[['문장', '유형', '극성', '시제', '확실성']]\n",
    "train_tmp = pd.get_dummies(train_tmp, columns=['유형', '극성', '시제', '확실성'])\n",
    "train_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dbfa9ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:27:11.990967Z",
     "start_time": "2022-12-16T09:27:11.872585Z"
    }
   },
   "outputs": [],
   "source": [
    "train_type = train_tmp.iloc[:,1:5].values.tolist()\n",
    "train_polarity = train_tmp.iloc[:,5:8].values.tolist()\n",
    "train_tense = train_tmp.iloc[:,8:11].values.tolist()\n",
    "train_certainty = train_tmp.iloc[:,11:13].values.tolist()\n",
    "train_labels = {\n",
    "    'type': train_type,\n",
    "    'polarity': train_polarity,\n",
    "    'tense': train_tense,\n",
    "    'certainty': train_certainty\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef65e1c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:27:20.802708Z",
     "start_time": "2022-12-16T09:27:20.781935Z"
    }
   },
   "outputs": [],
   "source": [
    "val_tmp = val[['문장', '유형', '극성', '시제', '확실성']]\n",
    "val_tmp = pd.get_dummies(val_tmp, columns=['유형', '극성', '시제', '확실성'])\n",
    "\n",
    "val_type = val_tmp.iloc[:,1:5].values.tolist()\n",
    "val_polarity = val_tmp.iloc[:,5:8].values.tolist()\n",
    "val_tense = val_tmp.iloc[:,8:11].values.tolist()\n",
    "val_certainty = val_tmp.iloc[:,11:13].values.tolist()\n",
    "val_labels = {\n",
    "    'type': val_type,\n",
    "    'polarity': val_polarity,\n",
    "    'tense': val_tense,\n",
    "    'certainty': val_certainty\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a3df61f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:27:38.739938Z",
     "start_time": "2022-12-16T09:27:37.254235Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(SentenceTypeDataset(train_tmp, tokenizer, train_labels), batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0) # num_workers: how many subprocesses to use for data loading  \n",
    "val_dataloader = DataLoader(SentenceTypeDataset(val_tmp, tokenizer, val_labels), batch_size=CFG['BATCH_SIZE'], num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aa34bb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:27:45.267965Z",
     "start_time": "2022-12-16T09:27:45.263854Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SentenceClassifier(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78ffac2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T09:27:52.995953Z",
     "start_time": "2022-12-16T09:27:51.956743Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/414 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::cumsum.out' is not current implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msentence_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLEARNING_RATE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEPOCHS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkclue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36msentence_train\u001b[0;34m(model, train_dataloader, val_dataloader, learning_rate, epochs, model_nm)\u001b[0m\n\u001b[1;32m     27\u001b[0m certainty_label \u001b[38;5;241m=\u001b[39m certainty_label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 31\u001b[0m type_output, polarity_output, tense_output, certainty_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# from the forward function\u001b[39;00m\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m\u001b[38;5;241m*\u001b[39mcriterion[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m](type_output, type_label\u001b[38;5;241m.\u001b[39mfloat()) \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m     34\u001b[0m        \u001b[38;5;241m0.25\u001b[39m\u001b[38;5;241m*\u001b[39mcriterion[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolarity\u001b[39m\u001b[38;5;124m'\u001b[39m](polarity_output, polarity_label\u001b[38;5;241m.\u001b[39mfloat()) \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m     35\u001b[0m        \u001b[38;5;241m0.25\u001b[39m\u001b[38;5;241m*\u001b[39mcriterion[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtense\u001b[39m\u001b[38;5;124m'\u001b[39m](tense_output, tense_label\u001b[38;5;241m.\u001b[39mfloat()) \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m     36\u001b[0m        \u001b[38;5;241m0.25\u001b[39m\u001b[38;5;241m*\u001b[39mcriterion[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcertainty\u001b[39m\u001b[38;5;124m'\u001b[39m](certainty_output, certainty_label\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     37\u001b[0m total_loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniforge3/envs/lhs/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mSentenceClassifier.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# input_ids : token's id / attention_mask : make a model to focus on which token\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     klue_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mklue\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(klue_out)\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/miniforge3/envs/lhs/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/lhs/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:839\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    837\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 839\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    847\u001b[0m     embedding_output,\n\u001b[1;32m    848\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    856\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    857\u001b[0m )\n\u001b[1;32m    858\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/lhs/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/lhs/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:101\u001b[0m, in \u001b[0;36mRobertaEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;66;03m# Create the position ids from the input token ids. Any padded tokens remain padded.\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m         position_ids \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_position_ids_from_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m         position_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_position_ids_from_inputs_embeds(inputs_embeds)\n",
      "File \u001b[0;32m~/miniforge3/envs/lhs/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:1576\u001b[0m, in \u001b[0;36mcreate_position_ids_from_input_ids\u001b[0;34m(input_ids, padding_idx, past_key_values_length)\u001b[0m\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;66;03m# The series of casts and type-conversions here are carefully balanced to both work with ONNX export and XLA.\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m mask \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mne(padding_idx)\u001b[38;5;241m.\u001b[39mint()\n\u001b[0;32m-> 1576\u001b[0m incremental_indices \u001b[38;5;241m=\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype_as(mask) \u001b[38;5;241m+\u001b[39m past_key_values_length) \u001b[38;5;241m*\u001b[39m mask\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m incremental_indices\u001b[38;5;241m.\u001b[39mlong() \u001b[38;5;241m+\u001b[39m padding_idx\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::cumsum.out' is not current implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "sentence_train(model, train_dataloader, val_dataloader, CFG['LEARNING_RATE'], CFG['EPOCHS'], 'kclue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b3e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
