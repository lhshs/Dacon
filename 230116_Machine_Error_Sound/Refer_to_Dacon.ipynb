{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45bf2eea",
   "metadata": {},
   "source": [
    "https://dacon.io/competitions/official/235930/codeshare/6002?page=1&dtype=recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461e1021",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:14:07.153002Z",
     "start_time": "2022-12-17T07:13:58.399235Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q annoy\n",
    "!pip install -q FRUFS\n",
    "!pip install -q pacmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:14:14.622517Z",
     "start_time": "2022-12-17T07:14:13.652501Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b5b85eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:40:38.203538Z",
     "start_time": "2022-12-17T07:40:37.719781Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim import Optimizer, AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR, CyclicLR, OneCycleLR\n",
    "#from transformers.optimization import get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "#from transformers import get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 모델 학습을 위해 CUDA 환경 설정. : 지피유 설정\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b25bcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T08:21:15.220783Z",
     "start_time": "2022-12-15T08:21:15.216593Z"
    }
   },
   "outputs": [],
   "source": [
    "def MacroF1Score(y_true, y_pred):\n",
    "    f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3077fd31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:41:02.991125Z",
     "start_time": "2022-12-17T07:41:02.984022Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "LR = 1e-2\n",
    "BS = 16384 # 2의 제곱승꼴\n",
    "SEED = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d8ebe648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:41:11.158847Z",
     "start_time": "2022-12-17T07:41:11.148881Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b14fabf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:24:44.702111Z",
     "start_time": "2022-12-17T07:24:44.697884Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/lhs/Desktop/Machine_Sound_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:35:01.323485Z",
     "start_time": "2022-12-17T07:35:01.252481Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train_.csv').drop(columns=['Unnamed: 0']) # 모두 정상 Sample\n",
    "# train_df = train_df.iloc[:,2:]\n",
    "test = pd.read_csv('./test_.csv').drop(columns=['Unnamed: 0'])\n",
    "# test_df = test_df.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee800463-995c-43ac-a05d-f3988923add9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:35:30.712943Z",
     "start_time": "2022-12-17T07:35:30.706922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef get_mfcc_feature(df):\\n    features = []\\n    for path in tqdm(df['SAMPLE_PATH']):\\n        # librosa패키지를 사용하여 wav 파일 load\\n        y, sr = librosa.load(path, sr=CFG['SR'])\\n        \\n        # librosa패키지를 사용하여 mfcc 추출\\n        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CFG['N_MFCC'])\\n\\n        y_feature = []\\n        # 추출된 MFCC들의 평균을 Feature로 사용\\n        for e in mfcc:\\n            y_feature.append(np.mean(e))\\n        features.append(y_feature)\\n        \\n    return features\\n\\ntrain_features = get_mfcc_feature(train_df)\\ntest_features = get_mfcc_feature(test_df)\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def get_mfcc_feature(df):\n",
    "    features = []\n",
    "    for path in tqdm(df['SAMPLE_PATH']):\n",
    "        # librosa패키지를 사용하여 wav 파일 load\n",
    "        y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "        \n",
    "        # librosa패키지를 사용하여 mfcc 추출\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CFG['N_MFCC'])\n",
    "\n",
    "        y_feature = []\n",
    "        # 추출된 MFCC들의 평균을 Feature로 사용\n",
    "        for e in mfcc:\n",
    "            y_feature.append(np.mean(e))\n",
    "        features.append(y_feature)\n",
    "        \n",
    "    return features\n",
    "\n",
    "train_features = get_mfcc_feature(train_df)\n",
    "test_features = get_mfcc_feature(test_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "751ae163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:45:51.304191Z",
     "start_time": "2022-12-17T07:45:51.296615Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, x_val, Y_train, y_val = train_test_split(train, train['LABEL'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9ac5f101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:46:25.999491Z",
     "start_time": "2022-12-17T07:46:25.989512Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['LABEL'].values\n",
    "            self.df = self.df.drop(columns=['LABEL']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            x = torch.from_numpy(self.df[index]).type(torch.FloatTensor)\n",
    "            y = torch.FloatTensor([self.labels[index]])\n",
    "            return x, y\n",
    "            #self.x = self.df[index]\n",
    "            #self.y = self.labels[index]\n",
    "            #return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b675fd52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:47:05.940284Z",
     "start_time": "2022-12-17T07:47:05.932118Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(df = X_train, eval_mode=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=6)\n",
    "\n",
    "val_dataset = MyDataset(df = x_val, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e7d2a4be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:47:14.901755Z",
     "start_time": "2022-12-17T07:47:14.875986Z"
    }
   },
   "outputs": [],
   "source": [
    "# 계층 정규화\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-5):\n",
    "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "        \"\"\"\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.weight.data.fill_(1.0)\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon) # 계층정규화 완료\n",
    "        return self.weight * x + self.bias # wx+b\n",
    "        \n",
    "# 활성화 함수\n",
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "        \n",
    "class AutoEncoder1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder1, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.ln = LayerNorm(5000)\n",
    "        self.ln1 = LayerNorm(3500)\n",
    "        self.ln2 = LayerNorm(2000)\n",
    "        self.ln3 = LayerNorm(1000)\n",
    "        \n",
    "        self.upblock1 = nn.Sequential(nn.Linear(30, 1000), nn.BatchNorm1d(1000),GELU())\n",
    "        self.upblock2 = nn.Sequential(nn.Linear(1000,2000), nn.BatchNorm1d(2000),GELU())\n",
    "        self.upblock3 = nn.Sequential(nn.Linear(2000,3500), nn.BatchNorm1d(3500),GELU())\n",
    "        self.upblock4 = nn.Sequential(nn.Linear(3500,5000), nn.BatchNorm1d(5000),GELU())\n",
    "\n",
    "        self.downblock1 = nn.Sequential(nn.Linear(5000, 3500),nn.BatchNorm1d(3500),GELU())\n",
    "        self.downblock2 = nn.Sequential(nn.Linear(3500, 2000),nn.BatchNorm1d(2000),GELU())\n",
    "        self.downblock3 = nn.Sequential(nn.Linear(2000, 1000),nn.BatchNorm1d(1000),GELU())\n",
    "        self.downblock4 = nn.Sequential(nn.Linear(1000, 300),nn.BatchNorm1d(300),GELU())\n",
    "        \n",
    "        self.fclayer = nn.Sequential(nn.Linear(300,30))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        upblock1_out = self.upblock1(x) \n",
    "        upblock2_out = self.upblock2(upblock1_out)\n",
    "        upblock3_out = self.upblock3(upblock2_out)\n",
    "        upblock4_out = self.upblock4(upblock3_out)\n",
    "        \n",
    "        downblock1_out = self.downblock1(self.ln(upblock4_out)) \n",
    "        skipblock1 = downblock1_out + upblock3_out\n",
    "        downblock2_out = self.downblock2(self.ln1(skipblock1))\n",
    "        skipblock2 = downblock2_out + upblock2_out\n",
    "        downblock3_out = self.downblock3(self.ln2(skipblock2))\n",
    "        skipblock3 = downblock3_out + upblock1_out \n",
    "        downblock4_out = self.downblock4(self.ln3(skipblock3))\n",
    "        \n",
    "        x = self.fclayer(downblock4_out)\n",
    "         \n",
    "        return x # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a15ccd97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:47:20.370417Z",
     "start_time": "2022-12-17T07:47:20.353508Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        # Loss Function\n",
    "        self.criterion = nn.L1Loss().to(self.device)\n",
    "        \n",
    "    def fit(self):\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        avg = 1\n",
    "        for epoch in range(EPOCHS):\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            for x in iter(self.train_loader):\n",
    "                x = x.float().to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                _x = self.model(x)\n",
    "                loss = self.criterion(x, _x)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            score = self.validation(self.model, 0.95)\n",
    "            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(score)\n",
    "\n",
    "            if best_score <= score and avg > np.mean(train_loss):\n",
    "                best_score = score\n",
    "                avg = np.mean(train_loss)\n",
    "                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n",
    "                print('---------------------------')\n",
    "                print(f'Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
    "    \n",
    "    def validation(self, eval_model, thr):\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        eval_model.eval()\n",
    "        pred = []\n",
    "        true = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader):\n",
    "                x = x.float().to(self.device)\n",
    "\n",
    "                _x = self.model(x)\n",
    "                diff = cos(x, _x).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff)<thr, 1, 0).tolist()\n",
    "                pred += batch_pred\n",
    "                true += y.tolist()\n",
    "\n",
    "        return f1_score(true, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b35c06a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:47:21.845318Z",
     "start_time": "2022-12-17T07:47:21.702472Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f61a2fda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:47:22.568029Z",
     "start_time": "2022-12-17T07:47:22.163277Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, threshold_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs\u001b[39m\u001b[38;5;124m'\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     best_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     15\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/lhs/lib/python3.8/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/lhs/lib/python3.8/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/lhs/lib/python3.8/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/lhs/lib/python3.8/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniforge3/envs/lhs/lib/python3.8/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/lhs/lib/python3.8/site-packages/torch/cuda/__init__.py:211\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "model = nn.DataParallel(AutoEncoder1())\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, \n",
    "                                                       threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e23d471",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e91e8cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:35:34.441790Z",
     "start_time": "2022-12-17T07:35:34.438500Z"
    }
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'SR':16000,\n",
    "    'N_MFCC':128, # MFCC 벡터를 추출할 개수 (<=128)\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e967190-c87e-458a-b9cb-4399574fa696",
   "metadata": {},
   "source": [
    "## Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d26c1274",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T07:26:41.187584Z",
     "start_time": "2022-12-17T07:26:35.664793Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "import pacmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "704e4af1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T06:20:14.082488Z",
     "start_time": "2022-12-16T06:20:13.774727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_val)\n",
    "accuracy_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "379e7665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T06:20:19.324805Z",
     "start_time": "2022-12-16T06:20:18.335658Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(train_mfcc.iloc[:,:-1], train_mfcc['LABEL'])\n",
    "xgb_pred = model.predict(test_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "19521cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T06:20:19.327949Z",
     "start_time": "2022-12-16T06:20:19.325904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a634dee-9e6d-4332-898e-c564866d09c9",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c4d23dd-112c-44cb-b15d-fe3efadc0146",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T05:00:36.569912Z",
     "start_time": "2022-12-16T05:00:36.566007Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pred_label(model_pred):\n",
    "    # IsolationForest 모델 출력 (1:정상, -1:불량) 이므로 (0:정상, 1:불량)로 Label 변환\n",
    "    model_pred = np.where(model_pred == 1, 0, model_pred)\n",
    "    model_pred = np.where(model_pred == -1, 1, model_pred)\n",
    "    return model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45e03e85-2ffe-45e2-92fe-e564dc57a861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T05:00:41.458012Z",
     "start_time": "2022-12-16T05:00:41.324404Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_features) # model prediction\n",
    "# test_pred = get_pred_label(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "594ebdcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T05:01:02.041564Z",
     "start_time": "2022-12-16T05:01:02.036983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ...,  1,  1, -1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fecf184-57e8-4969-bce1-46da090bdd32",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "05157612-68bf-4102-a723-8c0ad0f76755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T06:14:25.992885Z",
     "start_time": "2022-12-16T06:14:25.985320Z"
    }
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "38b5a428-5c17-4056-a3fe-4f50e30412ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T06:20:23.213172Z",
     "start_time": "2022-12-16T06:20:23.201900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_ID</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SAMPLE_ID  LABEL\n",
       "0  TEST_0000      0\n",
       "1  TEST_0001      0\n",
       "2  TEST_0002      1\n",
       "3  TEST_0003      1\n",
       "4  TEST_0004      0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['LABEL'] = xgb_pred\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b18282a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T06:20:23.403013Z",
     "start_time": "2022-12-16T06:20:23.395644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    890\n",
       "0    624\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.LABEL.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "59c47261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T06:14:39.646234Z",
     "start_time": "2022-12-16T06:14:39.642940Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6c1c8567-eacd-4de3-b5e2-490102224edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T06:20:26.220821Z",
     "start_time": "2022-12-16T06:20:26.210111Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '/Users/lhs/Desktop/GitHub/Dacon/230116_Machine_Error_Sound/result/'\n",
    "\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
    "submit.to_csv(f'{path}{now}.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9870cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
